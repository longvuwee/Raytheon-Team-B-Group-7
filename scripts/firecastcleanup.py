# -*- coding: utf-8 -*-
"""FireCastCleanUp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QsWGHXC7u7ejs5VdScMppdiInDa-XQNY
"""

###Clean up

!pip install geopy

import pandas as pd
import numpy as np
import requests
import re
import geopy
import time
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter

df = pd.read_csv('CaliforniaFireModis20_21.csv')

df.head()

print(df.columns)

df = df.drop(columns=["scan", "track", "version", "frp"])

df.head()

print(f"The file contains {df.shape[0]} entries.")

# Group by 'acq_date' and sample 3 to 5 rows from each group
# We'll use a lambda function to randomly choose between 3 and 5 for each group
# Ensure the sample size is not larger than the group size
df_sampled = df.groupby('acq_date').apply(lambda x: x.sample(min(len(x), np.random.randint(3, 6)))).reset_index(drop=True)

# Display the number of entries in the sampled DataFrame
print(f"The sampled file contains {df_sampled.shape[0]} entries.")

# Save the sampled DataFrame to a new CSV file
df_sampled.to_csv('sampled_fire_data.csv', index=False)

print("Sampled data saved to 'sampled_fire_data.csv'")

df = pd.read_csv('sampled_fire_data.csv')

df.head()

print(f"The new file contains {df.shape[0]} entries.")

# Check for missing values in each row
rows_with_missing_data = df[df.isnull().any(axis=1)]

if not rows_with_missing_data.empty:
    print("Rows with missing data found:")
    display(rows_with_missing_data)
    # Remove rows with missing data
    df_cleaned = df.dropna()
    print(f"\nOriginal number of entries: {df.shape[0]}")
    print(f"Number of entries after removing rows with missing data: {df_cleaned.shape[0]}")
    df = df_cleaned
else:
    print("No missing data found in any row.")

df = pd.read_csv('CleanedCaliData.csv')

df.head()



display(df.head(20))